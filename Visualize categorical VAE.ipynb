{
 "cells": [
  {
   "cell_type": "code",
   "id": "584de240",
   "metadata": {},
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "training_images = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=transform, download=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3830f403",
   "metadata": {},
   "source": [
    "import torch\n",
    "from models import Encoder, Decoder, CategoricalVAE\n",
    "\n",
    "batch_size = 1\n",
    "train_dataset = torch.utils.data.DataLoader(\n",
    "    dataset=training_images, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "image_shape = next(iter(train_dataset))[0][0].shape  # [1, 28, 28]\n",
    "K = 26  # number of classes\n",
    "N = 3  # number of categorical distributions\n",
    "\n",
    "encoder = Encoder(N, K, image_shape)\n",
    "decoder = Decoder(N, K, image_shape)\n",
    "model = CategoricalVAE(encoder, decoder)\n",
    "\n",
    "state_dict = torch.load(\"outputs/default/save_49999.pt\", weights_only=True)\n",
    "model.load_state_dict(state_dict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "471e8653",
   "metadata": {},
   "source": [
    "batch = next(iter(train_dataset))\n",
    "x, labels = batch\n",
    "print(x.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1324136e",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x.squeeze(), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0e55b323",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    phi, x_hat = model(x, temperature=1.0)\n",
    "plt.imshow(x_hat.squeeze(), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "151c3ede",
   "metadata": {},
   "source": [
    "plt.imshow(phi.squeeze(), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ea4bdc4",
   "metadata": {},
   "source": [
    "from models import gumbel_softmax\n",
    "\n",
    "z_given_x = gumbel_softmax(phi, temperature=1.0, hard=True, batch=True)\n",
    "plt.imshow(z_given_x.squeeze(), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc5bf7ce",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(8.0, 8.0))\n",
    "grid = ImageGrid(\n",
    "    fig,\n",
    "    111,  # similar to subplot(111)\n",
    "    nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "    axes_pad=0.15,  # pad between axes in inch.\n",
    ")\n",
    "\n",
    "for ax in grid:\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    z_given_x = gumbel_softmax(phi, temperature=5.0, hard=True, batch=True)\n",
    "    with torch.no_grad():\n",
    "        x_hat = model.decoder(z_given_x)\n",
    "    ax.imshow(x_hat.squeeze(), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
